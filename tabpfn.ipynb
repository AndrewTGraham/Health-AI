{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531f0f1b-3569-48bc-a374-0232ba2be269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT first with internet option turned on\n",
    "# Use GPU env\n",
    "\n",
    "# !pip download tabpfn --no-deps -d pip-packages\n",
    "# !pip install tabpfn\n",
    "# from tabpfn import TabPFNClassifier\n",
    "# TabPFNClassifier(N_ensemble_configurations=64,device='cuda:0')\n",
    "\n",
    "# !mv /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/prior_diff_real_checkpoint_n_0_epoch_100.cpkt pip-packages/\n",
    "# !zip -r pip-packages.zip pip-packages\n",
    "\n",
    "# now you need to download the zip and upload it as dataset with the plus in the top left\n",
    "# then you need to add it to the notebook as data on the right, and name it `pip-packages-icr`\n",
    "\n",
    "# now you can turn internet off and still install, like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449a0466-9d1f-40cb-994e-fce41b221930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr/pip-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e957651f-71eb-4910-8932-87b7c44457cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "# !cp /kaggle/input/pip-packages-icr/pip-packages/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae0f560-1b21-427a-a391-95f909689a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B' 'A']\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 77>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m m \u001b[38;5;241m=\u001b[39m WeightedEns()\n\u001b[0;32m     76\u001b[0m m\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(pred_and_time),np\u001b[38;5;241m.\u001b[39marray(greeksdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlpha\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m---> 77\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_pred_and_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (m\u001b[38;5;241m.\u001b[39mclasses_[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     79\u001b[0m p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((p[:,:\u001b[38;5;241m1\u001b[39m],np\u001b[38;5;241m.\u001b[39msum(p[:,\u001b[38;5;241m1\u001b[39m:],\u001b[38;5;241m1\u001b[39m,keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)), \u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mWeightedEns.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m     58\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimp\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m---> 59\u001b[0m     ps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([cl\u001b[38;5;241m.\u001b[39mpredict_proba(X) \u001b[38;5;28;01mfor\u001b[39;00m cl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifiers])\n\u001b[0;32m     60\u001b[0m     p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(ps,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     61\u001b[0m     class_0_est_instances \u001b[38;5;241m=\u001b[39m p[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m     58\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimp\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m---> 59\u001b[0m     ps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\u001b[43mcl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m cl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifiers])\n\u001b[0;32m     60\u001b[0m     p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(ps,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     61\u001b[0m     class_0_est_instances \u001b[38;5;241m=\u001b[39m p[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tabpfn\\scripts\\transformer_prediction_interface.py:266\u001b[0m, in \u001b[0;36mTabPFNClassifier.predict_proba\u001b[1;34m(self, X, normalize_with_test, return_logits)\u001b[0m\n\u001b[0;32m    262\u001b[0m y_full \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_full, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    264\u001b[0m eval_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 266\u001b[0m prediction \u001b[38;5;241m=\u001b[39m transformer_predict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m2\u001b[39m], X_full, y_full, eval_pos,\n\u001b[0;32m    267\u001b[0m                                  device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[0;32m    268\u001b[0m                                  style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstyle,\n\u001b[0;32m    269\u001b[0m                                  inference_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    270\u001b[0m                                  preprocess_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_preprocess_mode \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    271\u001b[0m                                  normalize_with_test\u001b[38;5;241m=\u001b[39mnormalize_with_test,\n\u001b[0;32m    272\u001b[0m                                  N_ensemble_configurations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_ensemble_configurations,\n\u001b[0;32m    273\u001b[0m                                  softmax_temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature,\n\u001b[0;32m    274\u001b[0m                                  multiclass_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulticlass_decoder,\n\u001b[0;32m    275\u001b[0m                                  feature_shift_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_shift_decoder,\n\u001b[0;32m    276\u001b[0m                                  differentiable_hps_as_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdifferentiable_hps_as_style,\n\u001b[0;32m    277\u001b[0m                                  seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed,\n\u001b[0;32m    278\u001b[0m                                  return_logits\u001b[38;5;241m=\u001b[39mreturn_logits,\n\u001b[0;32m    279\u001b[0m                                  no_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad,\n\u001b[0;32m    280\u001b[0m                                  batch_size_inference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size_inference,\n\u001b[0;32m    281\u001b[0m                                  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mget_params_from_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc))\n\u001b[0;32m    282\u001b[0m prediction_, y_ \u001b[38;5;241m=\u001b[39m prediction\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m), y_full\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()[eval_pos:]\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction_\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad \u001b[38;5;28;01melse\u001b[39;00m prediction_\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tabpfn\\scripts\\transformer_prediction_interface.py:517\u001b[0m, in \u001b[0;36mtransformer_predict\u001b[1;34m(model, eval_xs, eval_ys, eval_position, device, max_features, style, inference_mode, num_classes, extend_features, normalize_with_test, normalize_to_ranking, softmax_temperature, multiclass_decoder, preprocess_transform, categorical_feats, feature_shift_decoder, N_ensemble_configurations, batch_size_inference, differentiable_hps_as_style, average_logits, fp16_inference, normalize_with_sqrt, seed, no_grad, return_logits, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    515\u001b[0m                         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 517\u001b[0m     output_batch \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftmax_temperature_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39mfp16_inference):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\checkpoint.py:249\u001b[0m, in \u001b[0;36mcheckpoint\u001b[1;34m(function, use_reentrant, *args, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected keyword arguments: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m kwargs))\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_reentrant:\n\u001b[1;32m--> 249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _checkpoint_without_reentrant(\n\u001b[0;32m    252\u001b[0m         function,\n\u001b[0;32m    253\u001b[0m         preserve,\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    256\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\checkpoint.py:107\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[1;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[0;32m    104\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 107\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tabpfn\\scripts\\transformer_prediction_interface.py:353\u001b[0m, in \u001b[0;36mtransformer_predict.<locals>.predict\u001b[1;34m(eval_xs, eval_ys, used_style, softmax_temperature, return_logits)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m inference_mode_call:\n\u001b[0;32m    352\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 353\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mused_style\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_xs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mused_style\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_xs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_ys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m            \u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_position\u001b[49m\u001b[43m)\u001b[49m[:, :, \u001b[38;5;241m0\u001b[39m:num_classes]\n\u001b[0;32m    357\u001b[0m     output \u001b[38;5;241m=\u001b[39m output[:, :, \u001b[38;5;241m0\u001b[39m:num_classes] \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(softmax_temperature)\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_logits:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tabpfn\\transformer.py:141\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[1;34m(self, src, src_mask, single_eval_pos)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src)\n\u001b[1;32m--> 141\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(output)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output[single_eval_pos\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(style_src)\u001b[38;5;241m+\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_att_embeddings\u001b[38;5;241m.\u001b[39mnum_embeddings \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_att_embeddings \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m):]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tabpfn\\transformer.py:227\u001b[0m, in \u001b[0;36mTransformerEncoderDiffInit.forward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    224\u001b[0m output \u001b[38;5;241m=\u001b[39m src\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 227\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tabpfn\\layer.py:108\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m src_key_padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    107\u001b[0m single_eval_position \u001b[38;5;241m=\u001b[39m src_mask\n\u001b[1;32m--> 108\u001b[0m src_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    109\u001b[0m src_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(src_[single_eval_position:], src_[:single_eval_position], src_[:single_eval_position])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    110\u001b[0m src2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([src_left, src_right], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1205\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1192\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1203\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1205\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:5340\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5338\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(q_scaled, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   5339\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m softmax(attn_output_weights, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 5340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdropout_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m:\n\u001b[0;32m   5341\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m dropout(attn_output_weights, p\u001b[38;5;241m=\u001b[39mdropout_p)\n\u001b[0;32m   5343\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(attn_output_weights, v)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# LOAD THE DATA\n",
    "\n",
    "BASE_DIR = ('C:/Users/andre/OneDrive/Desktop/GitHub/Health-AI/'\n",
    "            'icr-identify-age-related-conditions')\n",
    "# Import data directly as H2O frame\n",
    "maindf = pd.read_csv(f'{BASE_DIR}/train.csv')\n",
    "greeksdf = pd.read_csv(f'{BASE_DIR}/greeks.csv')\n",
    "testdf = pd.read_csv(f'{BASE_DIR}/test.csv')\n",
    "\n",
    "print(maindf.EJ.unique())\n",
    "first_cat = maindf.EJ.unique()[0]\n",
    "maindf.EJ = maindf.EJ.eq(first_cat).astype('int')\n",
    "testdf.EJ = testdf.EJ.eq(first_cat).astype('int')\n",
    "\n",
    "# Greeks contains time information that we can use, we just need to parse it to int / nan.\n",
    "\n",
    "from datetime import date, datetime\n",
    "times = greeksdf.Epsilon.copy()\n",
    "times[greeksdf.Epsilon != 'Unknown'] = greeksdf.Epsilon[greeksdf.Epsilon != 'Unknown'].map(lambda x: datetime.strptime(x,'%m/%d/%Y').toordinal())\n",
    "times[greeksdf.Epsilon == 'Unknown'] = np.nan\n",
    "\n",
    "# Set predictor and target columns\n",
    "target = 'Class'\n",
    "predictors = [n for n in maindf.columns if n != target and n != 'Id']\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import xgboost\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "\n",
    "class WeightedEns(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.classifiers = [xgboost.XGBClassifier(),TabPFNClassifier(N_ensemble_configurations=64,device='cpu')]\n",
    "        self.imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        cls, y = np.unique(y, return_inverse=True)\n",
    "        self.classes_ = cls\n",
    "        X = self.imp.fit_transform(X)\n",
    "        for cl in self.classifiers:\n",
    "            cl.fit(X,y)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = self.imp.transform(X)\n",
    "        ps = np.stack([cl.predict_proba(X) for cl in self.classifiers])\n",
    "        p = np.mean(ps,axis=0)\n",
    "        class_0_est_instances = p[:,0].sum()\n",
    "        others_est_instances = p[:,1:].sum()\n",
    "        # we reweight the probs, since the loss is also balanced like this\n",
    "        # our models out of the box optimize CE\n",
    "        # with these changes they optimize balanced CE\n",
    "        new_p = p * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(p.shape[1])]])\n",
    "        return new_p / np.sum(new_p,axis=1,keepdims=1)\n",
    "    \n",
    "pred_and_time = pd.concat((maindf[predictors], times), 1)\n",
    "\n",
    "\n",
    "test_predictors = np.array(testdf[predictors])\n",
    "test_pred_and_time = np.concatenate((test_predictors, np.zeros((len(test_predictors),1)) + pred_and_time.Epsilon.max()+1),1)\n",
    "\n",
    "m = WeightedEns()\n",
    "m.fit(np.array(pred_and_time),np.array(greeksdf['Alpha']))\n",
    "p = m.predict_proba(test_pred_and_time)\n",
    "assert (m.classes_[0] == 'A')\n",
    "p = np.concatenate((p[:,:1],np.sum(p[:,1:],1,keepdims=True)), 1)\n",
    "result_df = pd.concat((testdf['Id'],pd.DataFrame(p, columns=('class_0', 'class_1'))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a4293-cc83-44bf-8ed7-cbec2d55ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def competition_log_loss(y_true, y_pred):\n",
    "    # Updated Formula (actual eval metric)\n",
    "    # y_true: correct labels 0, 1\n",
    "    # y_pred: predicted probabilities of class=1\n",
    "    # Implements the Evaluation equation with w_0 = w_1 = 1.\n",
    "    # Calculate the number of observations for each class\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    # Calculate the predicted probabilities for each class\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    # Calculate the average log loss for each class\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0)) / N_0\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1)) / N_1\n",
    "    # return the (not further weighted) average of the averages\n",
    "    return (log_loss_0 + log_loss_1)/2\n",
    "\n",
    "competition_log_loss(y_valid, valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2458ad-02c4-4f19-852a-cd0527dd955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#79############################################################################\n",
    "#72#####################################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9664643-da49-489f-bf30-a514c0f56d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = ('C:/Users/andre/OneDrive/Desktop/GitHub/Health-AI/'\n",
    "            'icr-identify-age-related-conditions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72deaf5f-f3e4-4ea4-ba68-7ce5c0e7f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # This is the old formula. It is wrong.\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    balanced_log_loss_score = (\n",
    "        -w0/nc[0]\n",
    "        * (np.sum(np.where(y_true==0,1,0)\n",
    "        * np.log(1-y_pred))) - w1/nc[1]\n",
    "        * (np.sum(np.where(y_true!=0,1,0)\n",
    "        * np.log(y_pred)))\n",
    "        ) / (w0+w1)\n",
    "    return balanced_log_loss_score\n",
    "\n",
    "def competition_log_loss(y_true, y_pred):\n",
    "    # Updated Formula (actual eval metric)\n",
    "    # y_true: correct labels 0, 1\n",
    "    # y_pred: predicted probabilities of class=1\n",
    "    # Implements the Evaluation equation with w_0 = w_1 = 1.\n",
    "    # Calculate the number of observations for each class\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    # Calculate the predicted probabilities for each class\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    # Calculate the average log loss for each class\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0)) / N_0\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1)) / N_1\n",
    "    # return the (not further weighted) average of the averages\n",
    "    return (log_loss_0 + log_loss_1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8cbf0-857b-4ad6-8096-6ce7f8302d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train   = pd.read_csv(filepath+'train.csv')\n",
    "test    = pd.read_csv(filepath+'test.csv')\n",
    "greeks  = pd.read_csv(filepath+'greeks.csv')\n",
    "example = pd.read_csv(filepath+'sample_submission.csv')\n",
    "\n",
    "\n",
    "def solve_whitespace(df):\n",
    "    # The files have whitespace issues\n",
    "    renamer={}\n",
    "    for col in df.columns:\n",
    "        renamer[col]=col.strip()\n",
    "    df.rename(columns=renamer,inplace=True)\n",
    "    return df\n",
    "train = solve_whitespace(train)\n",
    "test  = solve_whitespace(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46e2a7a-8017-4662-b712-23b64dff56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# The table greeks, has data only for the train dataset. The column Epsion\n",
    "# has the date that the data was collected. We know that for all the data\n",
    "# in test, the data was collected after all the data in train. I am\n",
    "# arbitrarily pretending that the test dataset came 1 year after the most\n",
    "# recent data in the train dataset. I am then assigning both datasets a\n",
    "# column Epsilon_a which is the the number of days before the test data\n",
    "# was recorded that each record was recorded.\n",
    "# \"\"\"\n",
    "# greeks['Epsilon'] = greeks['Epsilon'].replace({\"Unknown\":np.NaN})\n",
    "# greeks['Epsilon'] = pd.to_datetime(greeks['Epsilon'])\n",
    "\n",
    "# greeks[\"Epsilon_a\"] = greeks[\"Epsilon\"].max()+timedelta(days=365) - greeks[\"Epsilon\"]\n",
    "# greeks[\"Epsilon_a\"] = greeks[\"Epsilon_a\"].dt.days\n",
    "\n",
    "# train=train.merge(greeks[[\"Id\",\"Epsilon_a\"]])\n",
    "# test[\"Epsilon_a\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9bd1b-a98c-4d78-809f-f56b4adb30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring missing values\n",
    "\n",
    "train_summary = pd.DataFrame(train[1:].dtypes, columns=['data type'])\n",
    "train_summary['missing'] = train.isnull().sum().values \n",
    "desc = pd.DataFrame(train.describe(include='all').transpose())\n",
    "train_summary[train_summary['missing']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3010b4-54d9-480f-ae37-74045b6ba56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Numerical Variables\n",
    "num_cols = test.select_dtypes(include=['float64']).columns.tolist()\n",
    "figsize = (4*4, 20)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "for idx, col in enumerate(num_cols):\n",
    "    ax = plt.subplot(11,5, idx + 1)\n",
    "    sns.kdeplot(\n",
    "        data=train, hue='Class', fill=True,\n",
    "        x=col, palette=['#9E3F00', 'red'], legend=False\n",
    "    )\n",
    "            \n",
    "    ax.set_ylabel(''); ax.spines['top'].set_visible(False), \n",
    "    ax.set_xlabel(''); ax.spines['right'].set_visible(False)\n",
    "    ax.set_title(f'{col}', loc='right', \n",
    "                 weight='bold', fontsize=20)\n",
    "\n",
    "fig.suptitle(f'Features vs Target\\n\\n\\n', ha='center',  fontweight='bold', fontsize=21)\n",
    "fig.legend([1, 0], loc='upper center', bbox_to_anchor=(0.5, 0.96), fontsize=21, ncol=3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928c196-b717-4e3a-9898-a018390e1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_of_interest = \"GF\"\n",
    "print(train[train['Class']==0][col_of_interest].min())\n",
    "fig = px.histogram(train[train['Class']==0], x=col_of_interest,nbins=100)\n",
    "fig.show()\n",
    "fig = px.histogram(train[train['Class']==1], x=col_of_interest,nbins=100)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b67da90-6f22-47a1-b466-d9f8e1e7138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I observe that for a bunch of these variables, it seems like the Class 0\n",
    "(no diagnosis) is has a smaller standard deviation than the Class 1. This\n",
    "makes sense given how people with medical conditions will tend to have\n",
    "more extreme values. I wonder what sort of predictor power I could get\n",
    "if I simply looked at how far each person strays from the norm.\n",
    "\n",
    "unimodal_med_good_cols\n",
    "Let me, for all the unimodal distributions where it appears that Class 1\n",
    "has less kurtosis than Class 0 (the median seems to be good), calculate\n",
    "the distance from the Class 0 median and divide it by the class 0\n",
    "standard deviation.\n",
    "\n",
    "unimodal_med_bad_cols\n",
    "This is the opposite from unimodal_med_good_cols. I haven't decided how\n",
    "to handle this yet.\n",
    "\n",
    "low_pos_good_cols\n",
    "For Class 0, these have small positive values. The much higher positive\n",
    "values are indiciative of Class 1.\n",
    "\n",
    "other_cols\n",
    "semi_unimodal_cols\n",
    "bimodal_cols\n",
    "These need additional review. I'd especially like to look at all\n",
    "vairables broken down by the bimodal columns.\n",
    "\"\"\"\n",
    "unimodal_med_good_cols = [\n",
    "    \"AB\",\n",
    "    \"AF\",\n",
    "    \"AH\",\n",
    "    \"AM\",\n",
    "    \"AX\",\n",
    "    \"BD\",\n",
    "    \"BP\",\n",
    "    \"CC\",\n",
    "    \"CD\",\n",
    "    \"CH\",\n",
    "    \"CL\",\n",
    "    \"CR\",\n",
    "    \"CS\",\n",
    "    \"DF\",\n",
    "    \"DI\",\n",
    "    \"DL\",\n",
    "    \"DY\",\n",
    "    \"EB\",\n",
    "    \"FE\",\n",
    "    \"GB\",\n",
    "    \"GH\",\n",
    "]\n",
    "unimodal_med_bad_cols = [\n",
    "    \"EU\",\n",
    "]\n",
    "other_cols = [\n",
    "    \"AR\",\n",
    "    \"CB\",\n",
    "    \"CF\",\n",
    "    \"DV\",\n",
    "    \"EE\",\n",
    "    \"EG\",\n",
    "    \"EP\",\n",
    "    \"FC\",\n",
    "    \"FL\",\n",
    "    \"FS\",\n",
    "    \"GE\",\n",
    "    \"GF\",\n",
    "    \"GI\",\n",
    "]\n",
    "low_pos_good_cols = [\n",
    "    \"AY\",\n",
    "    \"BC\",\n",
    "    \"BR\",\n",
    "    \"BZ\",\n",
    "    \"DU\",\n",
    "    \"EH\",\n",
    "    \"FD\",\n",
    "    \"FR\",\n",
    "]\n",
    "semi_unimodal_cols = [\n",
    "    \"AZ\",\n",
    "    \"BN\",\n",
    "    \"BQ\",\n",
    "    \"CU\",\n",
    "    \"DA\",\n",
    "    \"DE\",\n",
    "    \"DH\",\n",
    "    \"DN\",\n",
    "    \"FI\",\n",
    "]\n",
    "bimodal_cols = [\n",
    "    \"CW\",\n",
    "    \"EL\",\n",
    "    \"GL\",\n",
    "]\n",
    "\n",
    "for col in unimodal_med_good_cols:\n",
    "    # Currently CC is giving nans and this is an issue when I run standard scaler so I'm skipping for now, resolve later.\n",
    "    if col==\"CC\": continue\n",
    "    train_class0_med = np.median(train[train['Class']==0][col])\n",
    "    train_class0_std = np.std(train[train['Class']==0][col])\n",
    "    train[col+'_a'] = train[col].apply(lambda x: (x-train_class0_med)/train_class0_std)\n",
    "    test[col+'_a'] = test[col].apply(lambda x: (x-train_class0_med)/train_class0_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f6b14-5e16-45d5-b139-a0858ecc0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df):\n",
    "    # Move categorical col to beginning of df\n",
    "    cols = list(df.columns)\n",
    "    cols.remove('EJ')\n",
    "    cols.insert(1,'EJ') # Temporarily I will remove this\n",
    "    df['EJ']=df['EJ'].replace({'A':0,'B':1})\n",
    "    df=df[cols]\n",
    "    \n",
    "    df=df.set_index('Id').copy(deep=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    EDIT: I commented this out since I am using XGB and don't need to impute\n",
    "    \n",
    "    7 columns have 1, 2, or 3 null values. If I try to find insights\n",
    "    from those, I will certainly overfit. I am simply imputing those\n",
    "    values. Due to my concerns of overfitting due to the tiny dataset,\n",
    "    I am going to only impute those using the mean/mode. Fancier methods\n",
    "    risk more overfitting. Columns BQ and EL each have 60 nulls (53 of\n",
    "    those overlap). For these columns I will create new columns that\n",
    "    mark them as having had nulls and then impute the missing values.\n",
    "    \"\"\"\n",
    "    # df['BQnull'] = 0\n",
    "    # df.loc[df['BQ'].isnull(),'BQnull'] = 1\n",
    "    # df['ELnull'] = 0\n",
    "    # df.loc[df['EL'].isnull(),'ELnull'] = 1\n",
    "    # # Impute values with mean and mode\n",
    "    # for col in df.columns:\n",
    "    #     if col in {'Class','Id','BQnull','ELnull'}: continue\n",
    "    #     if col=='EJ':\n",
    "    #         df[col].fillna(train[col].mode()[0],inplace=True)\n",
    "    #     else:\n",
    "    #         df[col].fillna(train[col].mean(),inplace=True)\n",
    "    \n",
    "    return df\n",
    "train=prep_df(train)\n",
    "test=prep_df(test)\n",
    "\n",
    "#Scale Columns\n",
    "num_cols = list(train.columns)\n",
    "num_cols.remove('Class')\n",
    "sc = StandardScaler()\n",
    "train[num_cols] = sc.fit_transform(train[num_cols])\n",
    "test[num_cols]  = sc.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81525922-df3e-425b-bbc1-6fab7f00039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedEnsemble(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.classifiers = [XGBClassifier(), TabPFNClassifier(N_ensemble_configurations=64, device='cuda:0')]\n",
    "        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        unique_classes, y = np.unique(y, return_inverse=True)\n",
    "        self.classes_ = unique_classes\n",
    "        for classifier in self.classifiers:\n",
    "            classifier.fit(X, y)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = self.imputer.transform(X)\n",
    "        probabilities = np.stack([classifier.predict_proba(X) for classifier in self.classifiers])\n",
    "        averaged_probabilities = np.mean(probabilities, axis=0)\n",
    "        class_0_est_instances = averaged_probabilities[:, 0].sum()\n",
    "        others_est_instances = averaged_probabilities[:, 1:].sum()\n",
    "        # Weighted probabilities based on class imbalance\n",
    "        new_probabilities = averaged_probabilities * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(averaged_probabilities.shape[1])]])\n",
    "        return new_probabilities / np.sum(new_probabilities, axis=1, keepdims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50c354-904b-473a-b20e-4f1251032965",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_count=4\n",
    "\n",
    "\n",
    "\n",
    "models=[]\n",
    "test_preds=[]\n",
    "oof_preds = np.zeros(len(train))\n",
    "\n",
    "# Separate into input variables and target variable.\n",
    "x = train.drop(columns='Class').copy(deep=True)\n",
    "y = train['Class'].copy(deep=True)\n",
    "del train\n",
    "\n",
    "weights = class_weight.compute_sample_weight('balanced', y)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=fold_count, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(x, y)):\n",
    "    fold_message = 'Fold '+str(fold+1)+' of '+str(fold_count)+' '\n",
    "    print(fold_message + '-' * (79-len(fold_message)))\n",
    "\n",
    "    x_train, y_train = x.iloc[train_idx], y.iloc[train_idx]\n",
    "    x_valid, y_valid = x.iloc[valid_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    # Build Model\n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=5000,\n",
    "        # I am using a scale_pos_weight becuase the evaluation function is a BALANCED log loss\n",
    "        scale_pos_weight=(len(y[y==0]) / len(y[y==1])),\n",
    "        random_state=1,\n",
    "        verbosity=0,\n",
    "        n_jobs=-1,\n",
    "        early_stopping_rounds=300,\n",
    "        learning_rate= 0.005, \n",
    "        max_depth=4,\n",
    "        # alpha=0.000463768723479341,\n",
    "        # colsample_bytree= 0.618829300507829,\n",
    "        # min_child_weight=9,\n",
    "        subsample=0.80,\n",
    "        eta=0.03,\n",
    "        gamma=1.5,\n",
    "        # booster='gbtree',\n",
    "        # grow_policy='depthwise',\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        verbose=0)\n",
    "    models.append(model)\n",
    "    \n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    test_preds.append(model.predict_proba(test)[:, 1])\n",
    "    \n",
    "    # Score OOF\n",
    "    print(\n",
    "        'Best Iteration:',\n",
    "        model.best_iteration)\n",
    "    print(\n",
    "        'Validation OOF balanced_log_loss (BAD)',\n",
    "        balanced_log_loss(y_valid, valid_preds))\n",
    "    print(\n",
    "        'Validation OOF competition_log_loss (GOOD)',\n",
    "        competition_log_loss(y_valid, valid_preds))\n",
    "    print(\n",
    "        'Validation OOF log_loss with sample_weights',\n",
    "        log_loss(y_valid, valid_preds, sample_weight=weights[valid_idx]))\n",
    "    print(\n",
    "        'Validation OOF log_loss',\n",
    "          log_loss(y_valid, valid_preds))\n",
    "    \n",
    "    oof_preds[valid_idx] = valid_preds\n",
    "    \n",
    "test_preds = np.mean(test_preds, axis=0)\n",
    "x['Pred']=oof_preds\n",
    "x.sort_index(inplace=True)\n",
    "y.sort_index(inplace=True)\n",
    "\n",
    "# Score OOF\n",
    "print(\n",
    "    '\\n\\nCombined OOF balanced_log_loss',\n",
    "    balanced_log_loss(y, oof_preds))\n",
    "print(\n",
    "    'Combined OOF competition_log_loss (GOOD)',\n",
    "    competition_log_loss(y_valid, valid_preds))\n",
    "print(\n",
    "    'Combined OOF log_loss with sample_weights',\n",
    "    log_loss(y, oof_preds, sample_weight=weights))\n",
    "print(\n",
    "    'Combined OOF log_loss',\n",
    "      log_loss(y, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c3f81-06fe-4887-bb9f-26023ca71e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for OOF predictions\n",
    "\n",
    "cm = confusion_matrix(y, x['Pred'].round())\n",
    "\n",
    "fig = px.imshow(cm,\n",
    "                text_auto=True,\n",
    "                labels=dict(x=\"Predicted\", y=\"Actual\", color=\"Count\"),\n",
    "                x=['0', '1'],\n",
    "                y=['0', '1']\n",
    "               )\n",
    "fig.update_xaxes(side=\"top\")\n",
    "fig.update_layout(width=500,height=500)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Feature Importance\n",
    "for model_pos in range(len(models)):\n",
    "    model_feature_importance = pd.DataFrame(\n",
    "        {\n",
    "            'Value':models[model_pos].feature_importances_,\n",
    "            'Feature':x.drop(columns='Pred').columns})\n",
    "    model_feature_importance['Model']=model_pos\n",
    "    if model_pos==0: feature_importance = model_feature_importance\n",
    "    else: feature_importance = pd.concat(\n",
    "        [feature_importance,model_feature_importance],axis=0)\n",
    "\n",
    "# Sort by total importance across all models\n",
    "total_feature_importance=feature_importance.groupby('Feature')['Value']\n",
    "total_feature_importance=total_feature_importance.sum().to_frame().reset_index()\n",
    "\n",
    "total_feature_importance.rename(\n",
    "    columns={'Value':'Total Value'},\n",
    "    inplace=True)\n",
    "feature_importance=feature_importance.merge(\n",
    "    total_feature_importance,\n",
    "    how = 'left',\n",
    "    on = 'Feature')\n",
    "# I just want to see top 10 and the special features\n",
    "feature_importance.sort_values(\n",
    "    by=[\"Total Value\",'Model'],\n",
    "    inplace=True)\n",
    "features_to_plot = feature_importance.drop_duplicates('Feature')\n",
    "features_to_plot = list(features_to_plot.iloc[-10:]['Feature'].values)\n",
    "for col in [\n",
    "    'EJ',\n",
    "    'BQnull',\n",
    "    'BQ',\n",
    "    'ELnull',\n",
    "    'EL'\n",
    "    ]:\n",
    "    if col not in features_to_plot:\n",
    "        features_to_plot.append(col)\n",
    "feature_importance=feature_importance[\n",
    "    feature_importance['Feature'].isin(features_to_plot)]\n",
    "feature_importance.sort_values(by=[\"Total Value\",'Model'],inplace=True)\n",
    "feature_importance.rename(columns={'Value':'Importance'},inplace=True)\n",
    "\n",
    "\n",
    "fig = px.bar(feature_importance, x='Importance', y='Feature', facet_col=\"Model\")\n",
    "fig.update_layout(width=1000,height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f5a7b-777d-4b54-9c98-9bbd2c09049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.copy(deep=True)\n",
    "submission['class_1'] = test_preds\n",
    "submission['class_0'] = [1 - x for x in test_preds]\n",
    "submission=submission[['class_0','class_1']]\n",
    "\n",
    "# Save the out of fold predictions on the train dataset\n",
    "x=x['Pred']\n",
    "\n",
    "#Save Output\n",
    "save_output=False\n",
    "\n",
    "if save_output:\n",
    "    outputFileName = 'v2'\n",
    "    outputFileName += (' ' + str(datetime.today())[:22].replace(':','.'))\n",
    "    x.to_csv(outputFileName + ' ooftrain.csv')\n",
    "    submission.to_csv(outputFileName + '.csv')\n",
    "\n",
    "submission.to_csv('submission.csv')\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
