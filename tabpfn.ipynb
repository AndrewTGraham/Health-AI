{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f0f1b-3569-48bc-a374-0232ba2be269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT first with internet option turned on\n",
    "# Use GPU env\n",
    "\n",
    "# !pip download tabpfn --no-deps -d pip-packages\n",
    "# !pip install tabpfn\n",
    "# from tabpfn import TabPFNClassifier\n",
    "# TabPFNClassifier(N_ensemble_configurations=64,device='cuda:0')\n",
    "\n",
    "# !mv /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/prior_diff_real_checkpoint_n_0_epoch_100.cpkt pip-packages/\n",
    "# !zip -r pip-packages.zip pip-packages\n",
    "\n",
    "# now you need to download the zip and upload it as dataset with the plus in the top left\n",
    "# then you need to add it to the notebook as data on the right, and name it `pip-packages-icr`\n",
    "\n",
    "# now you can turn internet off and still install, like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf739a9-4089-42c3-9e6a-6d7143ae770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "however"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a0466-9d1f-40cb-994e-fce41b221930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr/pip-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957651f-71eb-4910-8932-87b7c44457cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "# !cp /kaggle/input/pip-packages-icr/pip-packages/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0f560-1b21-427a-a391-95f909689a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# LOAD THE DATA\n",
    "\n",
    "BASE_DIR = ('C:/Users/andre/OneDrive/Desktop/GitHub/Health-AI/'\n",
    "            'icr-identify-age-related-conditions')\n",
    "# Import data directly as H2O frame\n",
    "maindf = pd.read_csv(f'{BASE_DIR}/train.csv')\n",
    "greeksdf = pd.read_csv(f'{BASE_DIR}/greeks.csv')\n",
    "testdf = pd.read_csv(f'{BASE_DIR}/test.csv')\n",
    "\n",
    "print(maindf.EJ.unique())\n",
    "first_cat = maindf.EJ.unique()[0]\n",
    "maindf.EJ = maindf.EJ.eq(first_cat).astype('int')\n",
    "testdf.EJ = testdf.EJ.eq(first_cat).astype('int')\n",
    "\n",
    "# Greeks contains time information that we can use, we just need to parse it to int / nan.\n",
    "\n",
    "from datetime import date, datetime\n",
    "times = greeksdf.Epsilon.copy()\n",
    "times[greeksdf.Epsilon != 'Unknown'] = greeksdf.Epsilon[greeksdf.Epsilon != 'Unknown'].map(lambda x: datetime.strptime(x,'%m/%d/%Y').toordinal())\n",
    "times[greeksdf.Epsilon == 'Unknown'] = np.nan\n",
    "\n",
    "# Set predictor and target columns\n",
    "target = 'Class'\n",
    "predictors = [n for n in maindf.columns if n != target and n != 'Id']\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import xgboost\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "\n",
    "class WeightedEns(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.classifiers = [xgboost.XGBClassifier(),TabPFNClassifier(N_ensemble_configurations=64,device='cpu')]\n",
    "        self.imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        cls, y = np.unique(y, return_inverse=True)\n",
    "        self.classes_ = cls\n",
    "        X = self.imp.fit_transform(X)\n",
    "        for cl in self.classifiers:\n",
    "            cl.fit(X,y)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = self.imp.transform(X)\n",
    "        ps = np.stack([cl.predict_proba(X) for cl in self.classifiers])\n",
    "        p = np.mean(ps,axis=0)\n",
    "        class_0_est_instances = p[:,0].sum()\n",
    "        others_est_instances = p[:,1:].sum()\n",
    "        # we reweight the probs, since the loss is also balanced like this\n",
    "        # our models out of the box optimize CE\n",
    "        # with these changes they optimize balanced CE\n",
    "        new_p = p * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(p.shape[1])]])\n",
    "        return new_p / np.sum(new_p,axis=1,keepdims=1)\n",
    "    \n",
    "pred_and_time = pd.concat((maindf[predictors], times), 1)\n",
    "\n",
    "\n",
    "test_predictors = np.array(testdf[predictors])\n",
    "test_pred_and_time = np.concatenate((test_predictors, np.zeros((len(test_predictors),1)) + pred_and_time.Epsilon.max()+1),1)\n",
    "\n",
    "m = WeightedEns()\n",
    "m.fit(np.array(pred_and_time),np.array(greeksdf['Alpha']))\n",
    "p = m.predict_proba(test_pred_and_time)\n",
    "assert (m.classes_[0] == 'A')\n",
    "p = np.concatenate((p[:,:1],np.sum(p[:,1:],1,keepdims=True)), 1)\n",
    "result_df = pd.concat((testdf['Id'],pd.DataFrame(p, columns=('class_0', 'class_1'))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a4293-cc83-44bf-8ed7-cbec2d55ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def competition_log_loss(y_true, y_pred):\n",
    "    # Updated Formula (actual eval metric)\n",
    "    # y_true: correct labels 0, 1\n",
    "    # y_pred: predicted probabilities of class=1\n",
    "    # Implements the Evaluation equation with w_0 = w_1 = 1.\n",
    "    # Calculate the number of observations for each class\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    # Calculate the predicted probabilities for each class\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    # Calculate the average log loss for each class\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0)) / N_0\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1)) / N_1\n",
    "    # return the (not further weighted) average of the averages\n",
    "    return (log_loss_0 + log_loss_1)/2\n",
    "\n",
    "competition_log_loss(y_valid, valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2458ad-02c4-4f19-852a-cd0527dd955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#79############################################################################\n",
    "#72#####################################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9664643-da49-489f-bf30-a514c0f56d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = ('C:/Users/andre/OneDrive/Desktop/GitHub/Health-AI/'\n",
    "            'icr-identify-age-related-conditions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72deaf5f-f3e4-4ea4-ba68-7ce5c0e7f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # This is the old formula. It is wrong.\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    balanced_log_loss_score = (\n",
    "        -w0/nc[0]\n",
    "        * (np.sum(np.where(y_true==0,1,0)\n",
    "        * np.log(1-y_pred))) - w1/nc[1]\n",
    "        * (np.sum(np.where(y_true!=0,1,0)\n",
    "        * np.log(y_pred)))\n",
    "        ) / (w0+w1)\n",
    "    return balanced_log_loss_score\n",
    "\n",
    "def competition_log_loss(y_true, y_pred):\n",
    "    # Updated Formula (actual eval metric)\n",
    "    # y_true: correct labels 0, 1\n",
    "    # y_pred: predicted probabilities of class=1\n",
    "    # Implements the Evaluation equation with w_0 = w_1 = 1.\n",
    "    # Calculate the number of observations for each class\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    # Calculate the predicted probabilities for each class\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    # Calculate the average log loss for each class\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0)) / N_0\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1)) / N_1\n",
    "    # return the (not further weighted) average of the averages\n",
    "    return (log_loss_0 + log_loss_1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8cbf0-857b-4ad6-8096-6ce7f8302d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train   = pd.read_csv(filepath+'train.csv')\n",
    "test    = pd.read_csv(filepath+'test.csv')\n",
    "greeks  = pd.read_csv(filepath+'greeks.csv')\n",
    "example = pd.read_csv(filepath+'sample_submission.csv')\n",
    "\n",
    "\n",
    "def solve_whitespace(df):\n",
    "    # The files have whitespace issues\n",
    "    renamer={}\n",
    "    for col in df.columns:\n",
    "        renamer[col]=col.strip()\n",
    "    df.rename(columns=renamer,inplace=True)\n",
    "    return df\n",
    "train = solve_whitespace(train)\n",
    "test  = solve_whitespace(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46e2a7a-8017-4662-b712-23b64dff56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# The table greeks, has data only for the train dataset. The column Epsion\n",
    "# has the date that the data was collected. We know that for all the data\n",
    "# in test, the data was collected after all the data in train. I am\n",
    "# arbitrarily pretending that the test dataset came 1 year after the most\n",
    "# recent data in the train dataset. I am then assigning both datasets a\n",
    "# column Epsilon_a which is the the number of days before the test data\n",
    "# was recorded that each record was recorded.\n",
    "# \"\"\"\n",
    "# greeks['Epsilon'] = greeks['Epsilon'].replace({\"Unknown\":np.NaN})\n",
    "# greeks['Epsilon'] = pd.to_datetime(greeks['Epsilon'])\n",
    "\n",
    "# greeks[\"Epsilon_a\"] = greeks[\"Epsilon\"].max()+timedelta(days=365) - greeks[\"Epsilon\"]\n",
    "# greeks[\"Epsilon_a\"] = greeks[\"Epsilon_a\"].dt.days\n",
    "\n",
    "# train=train.merge(greeks[[\"Id\",\"Epsilon_a\"]])\n",
    "# test[\"Epsilon_a\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9bd1b-a98c-4d78-809f-f56b4adb30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring missing values\n",
    "\n",
    "train_summary = pd.DataFrame(train[1:].dtypes, columns=['data type'])\n",
    "train_summary['missing'] = train.isnull().sum().values \n",
    "desc = pd.DataFrame(train.describe(include='all').transpose())\n",
    "train_summary[train_summary['missing']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3010b4-54d9-480f-ae37-74045b6ba56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Numerical Variables\n",
    "num_cols = test.select_dtypes(include=['float64']).columns.tolist()\n",
    "figsize = (4*4, 20)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "for idx, col in enumerate(num_cols):\n",
    "    ax = plt.subplot(11,5, idx + 1)\n",
    "    sns.kdeplot(\n",
    "        data=train, hue='Class', fill=True,\n",
    "        x=col, palette=['#9E3F00', 'red'], legend=False\n",
    "    )\n",
    "            \n",
    "    ax.set_ylabel(''); ax.spines['top'].set_visible(False), \n",
    "    ax.set_xlabel(''); ax.spines['right'].set_visible(False)\n",
    "    ax.set_title(f'{col}', loc='right', \n",
    "                 weight='bold', fontsize=20)\n",
    "\n",
    "fig.suptitle(f'Features vs Target\\n\\n\\n', ha='center',  fontweight='bold', fontsize=21)\n",
    "fig.legend([1, 0], loc='upper center', bbox_to_anchor=(0.5, 0.96), fontsize=21, ncol=3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928c196-b717-4e3a-9898-a018390e1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_of_interest = \"GF\"\n",
    "print(train[train['Class']==0][col_of_interest].min())\n",
    "fig = px.histogram(train[train['Class']==0], x=col_of_interest,nbins=100)\n",
    "fig.show()\n",
    "fig = px.histogram(train[train['Class']==1], x=col_of_interest,nbins=100)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b67da90-6f22-47a1-b466-d9f8e1e7138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I observe that for a bunch of these variables, it seems like the Class 0\n",
    "(no diagnosis) is has a smaller standard deviation than the Class 1. This\n",
    "makes sense given how people with medical conditions will tend to have\n",
    "more extreme values. I wonder what sort of predictor power I could get\n",
    "if I simply looked at how far each person strays from the norm.\n",
    "\n",
    "unimodal_med_good_cols\n",
    "Let me, for all the unimodal distributions where it appears that Class 1\n",
    "has less kurtosis than Class 0 (the median seems to be good), calculate\n",
    "the distance from the Class 0 median and divide it by the class 0\n",
    "standard deviation.\n",
    "\n",
    "unimodal_med_bad_cols\n",
    "This is the opposite from unimodal_med_good_cols. I haven't decided how\n",
    "to handle this yet.\n",
    "\n",
    "low_pos_good_cols\n",
    "For Class 0, these have small positive values. The much higher positive\n",
    "values are indiciative of Class 1.\n",
    "\n",
    "other_cols\n",
    "semi_unimodal_cols\n",
    "bimodal_cols\n",
    "These need additional review. I'd especially like to look at all\n",
    "vairables broken down by the bimodal columns.\n",
    "\"\"\"\n",
    "unimodal_med_good_cols = [\n",
    "    \"AB\",\n",
    "    \"AF\",\n",
    "    \"AH\",\n",
    "    \"AM\",\n",
    "    \"AX\",\n",
    "    \"BD\",\n",
    "    \"BP\",\n",
    "    \"CC\",\n",
    "    \"CD\",\n",
    "    \"CH\",\n",
    "    \"CL\",\n",
    "    \"CR\",\n",
    "    \"CS\",\n",
    "    \"DF\",\n",
    "    \"DI\",\n",
    "    \"DL\",\n",
    "    \"DY\",\n",
    "    \"EB\",\n",
    "    \"FE\",\n",
    "    \"GB\",\n",
    "    \"GH\",\n",
    "]\n",
    "unimodal_med_bad_cols = [\n",
    "    \"EU\",\n",
    "]\n",
    "other_cols = [\n",
    "    \"AR\",\n",
    "    \"CB\",\n",
    "    \"CF\",\n",
    "    \"DV\",\n",
    "    \"EE\",\n",
    "    \"EG\",\n",
    "    \"EP\",\n",
    "    \"FC\",\n",
    "    \"FL\",\n",
    "    \"FS\",\n",
    "    \"GE\",\n",
    "    \"GF\",\n",
    "    \"GI\",\n",
    "]\n",
    "low_pos_good_cols = [\n",
    "    \"AY\",\n",
    "    \"BC\",\n",
    "    \"BR\",\n",
    "    \"BZ\",\n",
    "    \"DU\",\n",
    "    \"EH\",\n",
    "    \"FD\",\n",
    "    \"FR\",\n",
    "]\n",
    "semi_unimodal_cols = [\n",
    "    \"AZ\",\n",
    "    \"BN\",\n",
    "    \"BQ\",\n",
    "    \"CU\",\n",
    "    \"DA\",\n",
    "    \"DE\",\n",
    "    \"DH\",\n",
    "    \"DN\",\n",
    "    \"FI\",\n",
    "]\n",
    "bimodal_cols = [\n",
    "    \"CW\",\n",
    "    \"EL\",\n",
    "    \"GL\",\n",
    "]\n",
    "\n",
    "for col in unimodal_med_good_cols:\n",
    "    # Currently CC is giving nans and this is an issue when I run standard scaler so I'm skipping for now, resolve later.\n",
    "    if col==\"CC\": continue\n",
    "    train_class0_med = np.median(train[train['Class']==0][col])\n",
    "    train_class0_std = np.std(train[train['Class']==0][col])\n",
    "    train[col+'_a'] = train[col].apply(lambda x: (x-train_class0_med)/train_class0_std)\n",
    "    test[col+'_a'] = test[col].apply(lambda x: (x-train_class0_med)/train_class0_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f6b14-5e16-45d5-b139-a0858ecc0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df):\n",
    "    # Move categorical col to beginning of df\n",
    "    cols = list(df.columns)\n",
    "    cols.remove('EJ')\n",
    "    cols.insert(1,'EJ') # Temporarily I will remove this\n",
    "    df['EJ']=df['EJ'].replace({'A':0,'B':1})\n",
    "    df=df[cols]\n",
    "    \n",
    "    df=df.set_index('Id').copy(deep=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    EDIT: I commented this out since I am using XGB and don't need to impute\n",
    "    \n",
    "    7 columns have 1, 2, or 3 null values. If I try to find insights\n",
    "    from those, I will certainly overfit. I am simply imputing those\n",
    "    values. Due to my concerns of overfitting due to the tiny dataset,\n",
    "    I am going to only impute those using the mean/mode. Fancier methods\n",
    "    risk more overfitting. Columns BQ and EL each have 60 nulls (53 of\n",
    "    those overlap). For these columns I will create new columns that\n",
    "    mark them as having had nulls and then impute the missing values.\n",
    "    \"\"\"\n",
    "    # df['BQnull'] = 0\n",
    "    # df.loc[df['BQ'].isnull(),'BQnull'] = 1\n",
    "    # df['ELnull'] = 0\n",
    "    # df.loc[df['EL'].isnull(),'ELnull'] = 1\n",
    "    # # Impute values with mean and mode\n",
    "    # for col in df.columns:\n",
    "    #     if col in {'Class','Id','BQnull','ELnull'}: continue\n",
    "    #     if col=='EJ':\n",
    "    #         df[col].fillna(train[col].mode()[0],inplace=True)\n",
    "    #     else:\n",
    "    #         df[col].fillna(train[col].mean(),inplace=True)\n",
    "    \n",
    "    return df\n",
    "train=prep_df(train)\n",
    "test=prep_df(test)\n",
    "\n",
    "#Scale Columns\n",
    "num_cols = list(train.columns)\n",
    "num_cols.remove('Class')\n",
    "sc = StandardScaler()\n",
    "train[num_cols] = sc.fit_transform(train[num_cols])\n",
    "test[num_cols]  = sc.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81525922-df3e-425b-bbc1-6fab7f00039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedEnsemble(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.classifiers = [XGBClassifier(), TabPFNClassifier(N_ensemble_configurations=64, device='cuda:0')]\n",
    "        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        unique_classes, y = np.unique(y, return_inverse=True)\n",
    "        self.classes_ = unique_classes\n",
    "        for classifier in self.classifiers:\n",
    "            classifier.fit(X, y)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = self.imputer.transform(X)\n",
    "        probabilities = np.stack([classifier.predict_proba(X) for classifier in self.classifiers])\n",
    "        averaged_probabilities = np.mean(probabilities, axis=0)\n",
    "        class_0_est_instances = averaged_probabilities[:, 0].sum()\n",
    "        others_est_instances = averaged_probabilities[:, 1:].sum()\n",
    "        # Weighted probabilities based on class imbalance\n",
    "        new_probabilities = averaged_probabilities * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(averaged_probabilities.shape[1])]])\n",
    "        return new_probabilities / np.sum(new_probabilities, axis=1, keepdims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50c354-904b-473a-b20e-4f1251032965",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_count=4\n",
    "\n",
    "\n",
    "\n",
    "models=[]\n",
    "test_preds=[]\n",
    "oof_preds = np.zeros(len(train))\n",
    "\n",
    "# Separate into input variables and target variable.\n",
    "x = train.drop(columns='Class').copy(deep=True)\n",
    "y = train['Class'].copy(deep=True)\n",
    "del train\n",
    "\n",
    "weights = class_weight.compute_sample_weight('balanced', y)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=fold_count, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(x, y)):\n",
    "    fold_message = 'Fold '+str(fold+1)+' of '+str(fold_count)+' '\n",
    "    print(fold_message + '-' * (79-len(fold_message)))\n",
    "\n",
    "    x_train, y_train = x.iloc[train_idx], y.iloc[train_idx]\n",
    "    x_valid, y_valid = x.iloc[valid_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    # Build Model\n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=5000,\n",
    "        # I am using a scale_pos_weight becuase the evaluation function is a BALANCED log loss\n",
    "        scale_pos_weight=(len(y[y==0]) / len(y[y==1])),\n",
    "        random_state=1,\n",
    "        verbosity=0,\n",
    "        n_jobs=-1,\n",
    "        early_stopping_rounds=300,\n",
    "        learning_rate= 0.005, \n",
    "        max_depth=4,\n",
    "        # alpha=0.000463768723479341,\n",
    "        # colsample_bytree= 0.618829300507829,\n",
    "        # min_child_weight=9,\n",
    "        subsample=0.80,\n",
    "        eta=0.03,\n",
    "        gamma=1.5,\n",
    "        # booster='gbtree',\n",
    "        # grow_policy='depthwise',\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        verbose=0)\n",
    "    models.append(model)\n",
    "    \n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    test_preds.append(model.predict_proba(test)[:, 1])\n",
    "    \n",
    "    # Score OOF\n",
    "    print(\n",
    "        'Best Iteration:',\n",
    "        model.best_iteration)\n",
    "    print(\n",
    "        'Validation OOF balanced_log_loss (BAD)',\n",
    "        balanced_log_loss(y_valid, valid_preds))\n",
    "    print(\n",
    "        'Validation OOF competition_log_loss (GOOD)',\n",
    "        competition_log_loss(y_valid, valid_preds))\n",
    "    print(\n",
    "        'Validation OOF log_loss with sample_weights',\n",
    "        log_loss(y_valid, valid_preds, sample_weight=weights[valid_idx]))\n",
    "    print(\n",
    "        'Validation OOF log_loss',\n",
    "          log_loss(y_valid, valid_preds))\n",
    "    \n",
    "    oof_preds[valid_idx] = valid_preds\n",
    "    \n",
    "test_preds = np.mean(test_preds, axis=0)\n",
    "x['Pred']=oof_preds\n",
    "x.sort_index(inplace=True)\n",
    "y.sort_index(inplace=True)\n",
    "\n",
    "# Score OOF\n",
    "print(\n",
    "    '\\n\\nCombined OOF balanced_log_loss',\n",
    "    balanced_log_loss(y, oof_preds))\n",
    "print(\n",
    "    'Combined OOF competition_log_loss (GOOD)',\n",
    "    competition_log_loss(y_valid, valid_preds))\n",
    "print(\n",
    "    'Combined OOF log_loss with sample_weights',\n",
    "    log_loss(y, oof_preds, sample_weight=weights))\n",
    "print(\n",
    "    'Combined OOF log_loss',\n",
    "      log_loss(y, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c3f81-06fe-4887-bb9f-26023ca71e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for OOF predictions\n",
    "\n",
    "cm = confusion_matrix(y, x['Pred'].round())\n",
    "\n",
    "fig = px.imshow(cm,\n",
    "                text_auto=True,\n",
    "                labels=dict(x=\"Predicted\", y=\"Actual\", color=\"Count\"),\n",
    "                x=['0', '1'],\n",
    "                y=['0', '1']\n",
    "               )\n",
    "fig.update_xaxes(side=\"top\")\n",
    "fig.update_layout(width=500,height=500)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Feature Importance\n",
    "for model_pos in range(len(models)):\n",
    "    model_feature_importance = pd.DataFrame(\n",
    "        {\n",
    "            'Value':models[model_pos].feature_importances_,\n",
    "            'Feature':x.drop(columns='Pred').columns})\n",
    "    model_feature_importance['Model']=model_pos\n",
    "    if model_pos==0: feature_importance = model_feature_importance\n",
    "    else: feature_importance = pd.concat(\n",
    "        [feature_importance,model_feature_importance],axis=0)\n",
    "\n",
    "# Sort by total importance across all models\n",
    "total_feature_importance=feature_importance.groupby('Feature')['Value']\n",
    "total_feature_importance=total_feature_importance.sum().to_frame().reset_index()\n",
    "\n",
    "total_feature_importance.rename(\n",
    "    columns={'Value':'Total Value'},\n",
    "    inplace=True)\n",
    "feature_importance=feature_importance.merge(\n",
    "    total_feature_importance,\n",
    "    how = 'left',\n",
    "    on = 'Feature')\n",
    "# I just want to see top 10 and the special features\n",
    "feature_importance.sort_values(\n",
    "    by=[\"Total Value\",'Model'],\n",
    "    inplace=True)\n",
    "features_to_plot = feature_importance.drop_duplicates('Feature')\n",
    "features_to_plot = list(features_to_plot.iloc[-10:]['Feature'].values)\n",
    "for col in [\n",
    "    'EJ',\n",
    "    'BQnull',\n",
    "    'BQ',\n",
    "    'ELnull',\n",
    "    'EL'\n",
    "    ]:\n",
    "    if col not in features_to_plot:\n",
    "        features_to_plot.append(col)\n",
    "feature_importance=feature_importance[\n",
    "    feature_importance['Feature'].isin(features_to_plot)]\n",
    "feature_importance.sort_values(by=[\"Total Value\",'Model'],inplace=True)\n",
    "feature_importance.rename(columns={'Value':'Importance'},inplace=True)\n",
    "\n",
    "\n",
    "fig = px.bar(feature_importance, x='Importance', y='Feature', facet_col=\"Model\")\n",
    "fig.update_layout(width=1000,height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f5a7b-777d-4b54-9c98-9bbd2c09049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.copy(deep=True)\n",
    "submission['class_1'] = test_preds\n",
    "submission['class_0'] = [1 - x for x in test_preds]\n",
    "submission=submission[['class_0','class_1']]\n",
    "\n",
    "# Save the out of fold predictions on the train dataset\n",
    "x=x['Pred']\n",
    "\n",
    "#Save Output\n",
    "save_output=False\n",
    "\n",
    "if save_output:\n",
    "    outputFileName = 'v2'\n",
    "    outputFileName += (' ' + str(datetime.today())[:22].replace(':','.'))\n",
    "    x.to_csv(outputFileName + ' ooftrain.csv')\n",
    "    submission.to_csv(outputFileName + '.csv')\n",
    "\n",
    "submission.to_csv('submission.csv')\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
