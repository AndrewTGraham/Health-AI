{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2458ad-02c4-4f19-852a-cd0527dd955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#79############################################################################\n",
    "#72#####################################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9664643-da49-489f-bf30-a514c0f56d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = ('C:/Users/andre/OneDrive/Desktop/GitHub/Health-AI/'\n",
    "            'icr-identify-age-related-conditions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe8cbf0-857b-4ad6-8096-6ce7f8302d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train   = pd.read_csv(filepath+'train.csv')\n",
    "test    = pd.read_csv(filepath+'test.csv')\n",
    "greeks  = pd.read_csv(filepath+'greeks.csv')\n",
    "example = pd.read_csv(filepath+'sample_submission.csv')\n",
    "\n",
    "\n",
    "def solve_whitespace(df):\n",
    "    # The files have whitespace issues\n",
    "    renamer={}\n",
    "    for col in df.columns:\n",
    "        renamer[col]=col.strip()\n",
    "    df.rename(columns=renamer,inplace=True)\n",
    "    return df\n",
    "train = solve_whitespace(train)\n",
    "test  = solve_whitespace(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae9bd1b-a98c-4d78-809f-f56b4adb30cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data type</th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BQ</th>\n",
       "      <td>float64</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DU</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EL</th>\n",
       "      <td>float64</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FC</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS</th>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data type  missing\n",
       "BQ   float64       60\n",
       "CB   float64        2\n",
       "CC   float64        3\n",
       "DU   float64        1\n",
       "EL   float64       60\n",
       "FC   float64        1\n",
       "FL   float64        1\n",
       "FS   float64        2\n",
       "GL   float64        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring missing values\n",
    "\n",
    "train_summary = pd.DataFrame(train[1:].dtypes, columns=['data type'])\n",
    "train_summary['missing'] = train.isnull().sum().values \n",
    "desc = pd.DataFrame(train.describe(include='all').transpose())\n",
    "train_summary[train_summary['missing']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb4f6b14-5e16-45d5-b139-a0858ecc0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df):\n",
    "    # Move categorical col to beginning of df\n",
    "    cols = list(df.columns)\n",
    "    cols.remove('EJ')\n",
    "    cols.insert(1,'EJ') # Temporarily I will remove this\n",
    "    df['EJ']=df['EJ'].replace({'A':0,'B':1})\n",
    "    df=df[cols]\n",
    "    \n",
    "    df=df.set_index('Id').copy(deep=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    7 columns have 1, 2, or 3 null values. If I try to find insights\n",
    "    from those, I will certainly overfit. I am simply imputing those\n",
    "    values. Due to my concerns of overfitting due to the tiny dataset,\n",
    "    I am going to only impute those using the mean/mode. Fancier methods\n",
    "    risk more overfitting. Columns BQ and EL each have 60 nulls (53 of\n",
    "    those overlap). For these columns I will create new columns that\n",
    "    mark them as having had nulls and then impute the missing values.\n",
    "    \"\"\"\n",
    "    df['BQnull'] = 0\n",
    "    df.loc[df['BQ'].isnull(),'BQnull'] = 1\n",
    "    df['ELnull'] = 0\n",
    "    df.loc[df['EL'].isnull(),'ELnull'] = 1\n",
    "    # Impute values with mean and mode\n",
    "    for col in df.columns:\n",
    "        if col in {'Class','Id','BQnull','ELnull'}: continue\n",
    "        if col=='EJ':\n",
    "            df[col].fillna(train[col].mode()[0],inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(train[col].mean(),inplace=True)\n",
    "\n",
    "    return df\n",
    "train=prep_df(train)\n",
    "test=prep_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04cd3e1d-657c-4fbe-8835-517f9f2caa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    balanced_log_loss_score = (-w0/nc[0]*(np.sum(np.where(y_true==0,1,0) * np.log(1-y_pred))) - w1/nc[1]*(np.sum(np.where(y_true!=0,1,0) * np.log(y_pred)))) / (w0+w1)\n",
    "    return balanced_log_loss_score\n",
    "\n",
    "def xgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459dbf8d-9cd7-4f36-b5d8-a0db38ea85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldCount=3\n",
    "\n",
    "train = shuffle(train, random_state=1)\n",
    "# Separate into input variables and target variable.\n",
    "x = train.drop(columns='Class').copy(deep=True)\n",
    "y = train['Class'].copy(deep=True)\n",
    "del train\n",
    "\n",
    "rowsPerFold=len(x)//foldCount\n",
    "BonusRowsInLastFold=len(x)%foldCount\n",
    "\n",
    "\n",
    "resultslist=[]\n",
    "oof_results=[]\n",
    "\n",
    "for iteration in range(foldCount):\n",
    "    print('starting iteration',iteration)\n",
    "   \n",
    "    # Choosing data to include in this\n",
    "    firstRow=iteration*rowsPerFold\n",
    "    if iteration+1==foldCount:\n",
    "        rowJustPastFold=firstRow+rowsPerFold+BonusRowsInLastFold\n",
    "    else: rowJustPastFold=firstRow+rowsPerFold\n",
    "    currentx = pd.concat([x.iloc[:firstRow],x.iloc[rowJustPastFold:]])\n",
    "    currenty = pd.concat([y.iloc[:firstRow],y.iloc[rowJustPastFold:]])\n",
    "\n",
    "    # Build Model\n",
    "    model = XGBClassifier(objective='binary:logistic',\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=1,\n",
    "                          verbosity=1,\n",
    "                          n_jobs=-1,\n",
    "                          learning_rate= 0.005, \n",
    "                          max_depth=4,\n",
    "                          colsample_bytree= 0.50,\n",
    "                          subsample= 0.80,\n",
    "                          eta= 0.03,\n",
    "                          gamma= 1.5)\n",
    "    model.fit(currentx, currenty, verbose=1)\n",
    "\n",
    "    # Score Out of fold (oof)\n",
    "    for predictedVal in model.predict_proba(\n",
    "        x.iloc[firstRow:rowJustPastFold])[:,1]:\n",
    "        oof_results.append(predictedVal)\n",
    "\n",
    "    # Score Test Dataset\n",
    "    \"\"\"\n",
    "    Predict_proba returns a 2 dimensional array, but I will just keep the\n",
    "    probabilities of class_1. Hence [:,1]\n",
    "    \"\"\"\n",
    "    results = model.predict_proba(test)[:,1]\n",
    "    resultslist.append(results)\n",
    "\n",
    "\n",
    "# Average the predictions on the test dataset and store it\n",
    "results = []\n",
    "for pos in range(len(resultslist[0])):\n",
    "    prediction=0\n",
    "    for listX in range(foldCount):\n",
    "        prediction+=resultslist[listX][pos]\n",
    "    prediction=prediction/foldCount\n",
    "    results.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1203d98-9e99-4ac8-9129-040f2bb14619",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.copy(deep=True)\n",
    "submission['class_1'] = results\n",
    "submission['class_0'] = [1 - x for x in results]\n",
    "submission=submission[['class_0','class_1']]\n",
    "\n",
    "# Save the out of fold predictions on the train dataset\n",
    "x['Class']=oof_results\n",
    "x=x['Class']\n",
    "x.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f5a7b-777d-4b54-9c98-9bbd2c09049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_output=False\n",
    "\n",
    "if save_output:\n",
    "    outputFileName = 'v2'\n",
    "    outputFileName += (' ' + str(datetime.today())[:22].replace(':','.'))\n",
    "    x.to_csv(outputFileName + ' ooftrain.csv')\n",
    "    submission.to_csv(outputFileName + '.csv')\n",
    "    \n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
