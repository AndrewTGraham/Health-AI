{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2458ad-02c4-4f19-852a-cd0527dd955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#79############################################################################\n",
    "#72#####################################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9664643-da49-489f-bf30-a514c0f56d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = ('C:/Users/andre/OneDrive/Desktop/GitHub/Health-AI/'\n",
    "            'icr-identify-age-related-conditions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72deaf5f-f3e4-4ea4-ba68-7ce5c0e7f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # Someone else in the competition wrote this\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    balanced_log_loss_score = (\n",
    "        -w0/nc[0]\n",
    "        * (np.sum(np.where(y_true==0,1,0)\n",
    "        * np.log(1-y_pred))) - w1/nc[1]\n",
    "        * (np.sum(np.where(y_true!=0,1,0)\n",
    "        * np.log(y_pred)))\n",
    "        ) / (w0+w1)\n",
    "    return balanced_log_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8cbf0-857b-4ad6-8096-6ce7f8302d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train   = pd.read_csv(filepath+'train.csv')\n",
    "test    = pd.read_csv(filepath+'test.csv')\n",
    "greeks  = pd.read_csv(filepath+'greeks.csv')\n",
    "example = pd.read_csv(filepath+'sample_submission.csv')\n",
    "\n",
    "\n",
    "def solve_whitespace(df):\n",
    "    # The files have whitespace issues\n",
    "    renamer={}\n",
    "    for col in df.columns:\n",
    "        renamer[col]=col.strip()\n",
    "    df.rename(columns=renamer,inplace=True)\n",
    "    return df\n",
    "train = solve_whitespace(train)\n",
    "test  = solve_whitespace(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9bd1b-a98c-4d78-809f-f56b4adb30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring missing values\n",
    "\n",
    "train_summary = pd.DataFrame(train[1:].dtypes, columns=['data type'])\n",
    "train_summary['missing'] = train.isnull().sum().values \n",
    "desc = pd.DataFrame(train.describe(include='all').transpose())\n",
    "train_summary[train_summary['missing']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f6b14-5e16-45d5-b139-a0858ecc0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df):\n",
    "    # Move categorical col to beginning of df\n",
    "    cols = list(df.columns)\n",
    "    cols.remove('EJ')\n",
    "    cols.insert(1,'EJ') # Temporarily I will remove this\n",
    "    df['EJ']=df['EJ'].replace({'A':0,'B':1})\n",
    "    df=df[cols]\n",
    "    \n",
    "    df=df.set_index('Id').copy(deep=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    7 columns have 1, 2, or 3 null values. If I try to find insights\n",
    "    from those, I will certainly overfit. I am simply imputing those\n",
    "    values. Due to my concerns of overfitting due to the tiny dataset,\n",
    "    I am going to only impute those using the mean/mode. Fancier methods\n",
    "    risk more overfitting. Columns BQ and EL each have 60 nulls (53 of\n",
    "    those overlap). For these columns I will create new columns that\n",
    "    mark them as having had nulls and then impute the missing values.\n",
    "    \"\"\"\n",
    "    df['BQnull'] = 0\n",
    "    df.loc[df['BQ'].isnull(),'BQnull'] = 1\n",
    "    df['ELnull'] = 0\n",
    "    df.loc[df['EL'].isnull(),'ELnull'] = 1\n",
    "    # Impute values with mean and mode\n",
    "    for col in df.columns:\n",
    "        if col in {'Class','Id','BQnull','ELnull'}: continue\n",
    "        if col=='EJ':\n",
    "            df[col].fillna(train[col].mode()[0],inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(train[col].mean(),inplace=True)\n",
    "    \n",
    "    return df\n",
    "train=prep_df(train)\n",
    "test=prep_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11dd6be-f85b-40f5-970c-0356a2d359ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Columns\n",
    "num_cols = list(train.columns)\n",
    "num_cols.remove('Class')\n",
    "sc = StandardScaler()\n",
    "train[num_cols] = sc.fit_transform(train[num_cols])\n",
    "test[num_cols]  = sc.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459dbf8d-9cd7-4f36-b5d8-a0db38ea85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldCount=3\n",
    "\n",
    "train = shuffle(train, random_state=1)\n",
    "# Separate into input variables and target variable.\n",
    "x = train.drop(columns='Class').copy(deep=True)\n",
    "y = train['Class'].copy(deep=True)\n",
    "del train\n",
    "\n",
    "rowsPerFold=len(x)//foldCount\n",
    "BonusRowsInLastFold=len(x)%foldCount\n",
    "\n",
    "\n",
    "resultslist=[]\n",
    "oof_results=[]\n",
    "xgb_models=[]\n",
    "\n",
    "for iteration in range(foldCount):\n",
    "    print('\\nstarting iteration',iteration)\n",
    "   \n",
    "    # Choosing data to include in this\n",
    "    firstRow=iteration*rowsPerFold\n",
    "    if iteration+1==foldCount:\n",
    "        rowJustPastFold=firstRow+rowsPerFold+BonusRowsInLastFold\n",
    "    else: rowJustPastFold=firstRow+rowsPerFold\n",
    "    currentx = pd.concat([x.iloc[:firstRow],x.iloc[rowJustPastFold:]])\n",
    "    currenty = pd.concat([y.iloc[:firstRow],y.iloc[rowJustPastFold:]])\n",
    "\n",
    "    # Build Model\n",
    "    model = XGBClassifier(objective='binary:logistic',\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=1,\n",
    "                          verbosity=1,\n",
    "                          n_jobs=-1,\n",
    "                          learning_rate= 0.005, \n",
    "                          max_depth=4,\n",
    "                          colsample_bytree= 0.50,\n",
    "                          subsample= 0.80,\n",
    "                          eta= 0.03,\n",
    "                          gamma= 1.5)\n",
    "    model.fit(currentx, currenty, verbose=1)\n",
    "    xgb_models.append(model)\n",
    "\n",
    "    # Score Out of fold (oof)\n",
    "    model_oof = []\n",
    "    for predictedVal in model.predict_proba(\n",
    "        x.iloc[firstRow:rowJustPastFold])[:,1]:\n",
    "        oof_results.append(predictedVal)\n",
    "        model_oof.append(predictedVal)\n",
    "        \n",
    "    # Score on OOF\n",
    "    print(\n",
    "        'OOF balanced_log_loss',\n",
    "        balanced_log_loss(y.iloc[firstRow:rowJustPastFold],\n",
    "        model_oof))\n",
    "\n",
    "    # Score Test Dataset\n",
    "    \"\"\"\n",
    "    Predict_proba returns a 2 dimensional array, but I will just keep the\n",
    "    probabilities of class_1. Hence [:,1]\n",
    "    \"\"\"\n",
    "    results = model.predict_proba(test)[:,1]\n",
    "    resultslist.append(results)\n",
    "\n",
    "\n",
    "# Average the predictions on the test dataset and store it\n",
    "results = []\n",
    "for pos in range(len(resultslist[0])):\n",
    "    prediction=0\n",
    "    for listX in range(foldCount):\n",
    "        prediction+=resultslist[listX][pos]\n",
    "    prediction=prediction/foldCount\n",
    "    results.append(prediction)\n",
    "    \n",
    "x['Class']=oof_results\n",
    "x.sort_index(inplace=True)\n",
    "y.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8af61-1761-419b-b1c7-5f6bac9f8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score OOF\n",
    "print('OOF balanced_log_loss', balanced_log_loss(y, x['Class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c3f81-06fe-4887-bb9f-26023ca71e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for OOF predictions\n",
    "\n",
    "cm = confusion_matrix(y, x['Class'].round())\n",
    "\n",
    "fig = px.imshow(cm,\n",
    "                text_auto=True,\n",
    "                labels=dict(x=\"Predicted\", y=\"Actual\", color=\"Count\"),\n",
    "                x=['0', '1'],\n",
    "                y=['0', '1']\n",
    "               )\n",
    "fig.update_xaxes(side=\"top\")\n",
    "fig.update_layout(width=500,height=500)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d396b-21ae-4930-9497-b8196375d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "for model_pos in range(len(xgb_models)):\n",
    "    model_feature_importance = pd.DataFrame({'Value':xgb_models[model_pos].feature_importances_, 'Feature':x.drop(columns='Class').columns})\n",
    "    model_feature_importance['Model']=model_pos\n",
    "    if model_pos==0: feature_importance = model_feature_importance\n",
    "    else: feature_importance = pd.concat([feature_importance,model_feature_importance],axis=0)\n",
    "\n",
    "# Sort by total importance across all models\n",
    "total_feature_importance=feature_importance.groupby('Feature')['Value'].sum().to_frame().reset_index()\n",
    "total_feature_importance.rename(columns={'Value':'Total Value'},inplace=True)\n",
    "feature_importance=feature_importance.merge(total_feature_importance, how = 'left', on = 'Feature')\n",
    "# I just want to see top 10 and the special features\n",
    "feature_importance.sort_values(by=[\"Total Value\",'Model'],inplace=True)\n",
    "features_to_plot = list(feature_importance.drop_duplicates('Feature').iloc[-10:]['Feature'].values)\n",
    "for col in [\n",
    "    'EJ',\n",
    "    'BQnull',\n",
    "    'BQ',\n",
    "    'ELnull',\n",
    "    'EL'\n",
    "    ]:\n",
    "    if col not in features_to_plot:\n",
    "        features_to_plot.append(col)\n",
    "feature_importance=feature_importance[feature_importance['Feature'].isin(features_to_plot)]\n",
    "feature_importance.sort_values(by=[\"Total Value\",'Model'],inplace=True)\n",
    "feature_importance.rename(columns={'Value':'Importance'},inplace=True)\n",
    "\n",
    "\n",
    "fig = px.bar(feature_importance, x='Importance', y='Feature', facet_col=\"Model\")\n",
    "fig.update_layout(width=1000,height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1203d98-9e99-4ac8-9129-040f2bb14619",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.copy(deep=True)\n",
    "submission['class_1'] = results\n",
    "submission['class_0'] = [1 - x for x in results]\n",
    "submission=submission[['class_0','class_1']]\n",
    "\n",
    "# Save the out of fold predictions on the train dataset\n",
    "x=x['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f5a7b-777d-4b54-9c98-9bbd2c09049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_output=False\n",
    "\n",
    "if save_output:\n",
    "    outputFileName = 'v2'\n",
    "    outputFileName += (' ' + str(datetime.today())[:22].replace(':','.'))\n",
    "    x.to_csv(outputFileName + ' ooftrain.csv')\n",
    "    submission.to_csv(outputFileName + '.csv')\n",
    "    submission.to_csv('submission.csv')\n",
    "    \n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
