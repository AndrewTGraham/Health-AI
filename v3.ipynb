{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2458ad-02c4-4f19-852a-cd0527dd955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#79############################################################################\n",
    "#72#####################################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9664643-da49-489f-bf30-a514c0f56d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = ('C:/Users/andre/OneDrive/Desktop/GitHub/Health-AI/'\n",
    "            'icr-identify-age-related-conditions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72deaf5f-f3e4-4ea4-ba68-7ce5c0e7f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # Someone else in the competition wrote this\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    balanced_log_loss_score = (\n",
    "        -w0/nc[0]\n",
    "        * (np.sum(np.where(y_true==0,1,0)\n",
    "        * np.log(1-y_pred))) - w1/nc[1]\n",
    "        * (np.sum(np.where(y_true!=0,1,0)\n",
    "        * np.log(y_pred)))\n",
    "        ) / (w0+w1)\n",
    "    return balanced_log_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8cbf0-857b-4ad6-8096-6ce7f8302d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train   = pd.read_csv(filepath+'train.csv')\n",
    "test    = pd.read_csv(filepath+'test.csv')\n",
    "greeks  = pd.read_csv(filepath+'greeks.csv')\n",
    "example = pd.read_csv(filepath+'sample_submission.csv')\n",
    "\n",
    "\n",
    "def solve_whitespace(df):\n",
    "    # The files have whitespace issues\n",
    "    renamer={}\n",
    "    for col in df.columns:\n",
    "        renamer[col]=col.strip()\n",
    "    df.rename(columns=renamer,inplace=True)\n",
    "    return df\n",
    "train = solve_whitespace(train)\n",
    "test  = solve_whitespace(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9bd1b-a98c-4d78-809f-f56b4adb30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring missing values\n",
    "\n",
    "train_summary = pd.DataFrame(train[1:].dtypes, columns=['data type'])\n",
    "train_summary['missing'] = train.isnull().sum().values \n",
    "desc = pd.DataFrame(train.describe(include='all').transpose())\n",
    "train_summary[train_summary['missing']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f6b14-5e16-45d5-b139-a0858ecc0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df):\n",
    "    # Move categorical col to beginning of df\n",
    "    cols = list(df.columns)\n",
    "    cols.remove('EJ')\n",
    "    cols.insert(1,'EJ') # Temporarily I will remove this\n",
    "    df['EJ']=df['EJ'].replace({'A':0,'B':1})\n",
    "    df=df[cols]\n",
    "    \n",
    "    df=df.set_index('Id').copy(deep=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    7 columns have 1, 2, or 3 null values. If I try to find insights\n",
    "    from those, I will certainly overfit. I am simply imputing those\n",
    "    values. Due to my concerns of overfitting due to the tiny dataset,\n",
    "    I am going to only impute those using the mean/mode. Fancier methods\n",
    "    risk more overfitting. Columns BQ and EL each have 60 nulls (53 of\n",
    "    those overlap). For these columns I will create new columns that\n",
    "    mark them as having had nulls and then impute the missing values.\n",
    "    \"\"\"\n",
    "    df['BQnull'] = 0\n",
    "    df.loc[df['BQ'].isnull(),'BQnull'] = 1\n",
    "    df['ELnull'] = 0\n",
    "    df.loc[df['EL'].isnull(),'ELnull'] = 1\n",
    "    # Impute values with mean and mode\n",
    "    for col in df.columns:\n",
    "        if col in {'Class','Id','BQnull','ELnull'}: continue\n",
    "        if col=='EJ':\n",
    "            df[col].fillna(train[col].mode()[0],inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(train[col].mean(),inplace=True)\n",
    "    \n",
    "    return df\n",
    "train=prep_df(train)\n",
    "test=prep_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11dd6be-f85b-40f5-970c-0356a2d359ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Columns\n",
    "num_cols = list(train.columns)\n",
    "num_cols.remove('Class')\n",
    "sc = StandardScaler()\n",
    "train[num_cols] = sc.fit_transform(train[num_cols])\n",
    "test[num_cols]  = sc.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468a8c4-c368-4116-a369-feca8a157a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_count=5\n",
    "\n",
    "\n",
    "\n",
    "models=[]\n",
    "test_preds=[]\n",
    "oof_preds = np.zeros(len(train))\n",
    "\n",
    "# Separate into input variables and target variable.\n",
    "x = train.drop(columns='Class').copy(deep=True)\n",
    "y = train['Class'].copy(deep=True)\n",
    "del train\n",
    "\n",
    "weights = class_weight.compute_sample_weight('balanced', y)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=fold_count, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(x, y)):\n",
    "    fold_message = 'Fold '+str(fold+1)+' of '+str(fold_count)+' '\n",
    "    print(fold_message + '-' * (79-len(fold_message)))\n",
    "\n",
    "    x_train, y_train = x.iloc[train_idx], y.iloc[train_idx]\n",
    "    x_valid, y_valid = x.iloc[valid_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    # Build Model\n",
    "    model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=1000,\n",
    "        random_state=1,\n",
    "        verbosity=1,\n",
    "        n_jobs=-1,\n",
    "        # learning_rate= 0.005, \n",
    "        max_depth=4,\n",
    "        colsample_bytree= 0.67,\n",
    "        # subsample= 0.80,\n",
    "        eta= 0.2,\n",
    "        early_stopping_rounds=20,\n",
    "        # gamma= 1.5\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        sample_weight=weights[train_idx],\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        verbose=1)\n",
    "    models.append(model)\n",
    "    \n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    test_preds.append(model.predict_proba(test)[:, 1])\n",
    "    \n",
    "    # Score OOF\n",
    "    print(\n",
    "        'Validation OOF balanced_log_loss',\n",
    "        balanced_log_loss(y_valid, valid_preds))\n",
    "    print(\n",
    "        'Validation OOF log_loss with sample_weights',\n",
    "        log_loss(y_valid, valid_preds, sample_weight=weights[valid_idx]))\n",
    "    print(\n",
    "        'Validation OFF log_loss',\n",
    "          log_loss(y_valid, valid_preds))\n",
    "    \n",
    "    oof_preds[valid_idx] = valid_preds\n",
    "    \n",
    "test_preds = np.mean(test_preds, axis=0)\n",
    "x['Pred']=oof_preds\n",
    "x.sort_index(inplace=True)\n",
    "y.sort_index(inplace=True)\n",
    "\n",
    "# Score OOF\n",
    "print(\n",
    "    '\\n\\nCombined OOF balanced_log_loss',\n",
    "    balanced_log_loss(y, oof_preds))\n",
    "print(\n",
    "    'Combined OOF log_loss with sample_weights',\n",
    "    log_loss(y, oof_preds, sample_weight=weights))\n",
    "print(\n",
    "    'Combined OFF log_loss',\n",
    "      log_loss(y, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c3f81-06fe-4887-bb9f-26023ca71e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for OOF predictions\n",
    "\n",
    "cm = confusion_matrix(y, x['Pred'].round())\n",
    "\n",
    "fig = px.imshow(cm,\n",
    "                text_auto=True,\n",
    "                labels=dict(x=\"Predicted\", y=\"Actual\", color=\"Count\"),\n",
    "                x=['0', '1'],\n",
    "                y=['0', '1']\n",
    "               )\n",
    "fig.update_xaxes(side=\"top\")\n",
    "fig.update_layout(width=500,height=500)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d396b-21ae-4930-9497-b8196375d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "for model_pos in range(len(models)):\n",
    "    model_feature_importance = pd.DataFrame(\n",
    "        {\n",
    "            'Value':models[model_pos].feature_importances_,\n",
    "            'Feature':x.drop(columns='Pred').columns})\n",
    "    model_feature_importance['Model']=model_pos\n",
    "    if model_pos==0: feature_importance = model_feature_importance\n",
    "    else: feature_importance = pd.concat(\n",
    "        [feature_importance,model_feature_importance],axis=0)\n",
    "\n",
    "# Sort by total importance across all models\n",
    "total_feature_importance=feature_importance.groupby('Feature')['Value']\n",
    "total_feature_importance=total_feature_importance.sum().to_frame().reset_index()\n",
    "\n",
    "total_feature_importance.rename(\n",
    "    columns={'Value':'Total Value'},\n",
    "    inplace=True)\n",
    "feature_importance=feature_importance.merge(\n",
    "    total_feature_importance,\n",
    "    how = 'left',\n",
    "    on = 'Feature')\n",
    "# I just want to see top 10 and the special features\n",
    "feature_importance.sort_values(\n",
    "    by=[\"Total Value\",'Model'],\n",
    "    inplace=True)\n",
    "features_to_plot = feature_importance.drop_duplicates('Feature')\n",
    "features_to_plot = list(features_to_plot.iloc[-10:]['Feature'].values)\n",
    "for col in [\n",
    "    'EJ',\n",
    "    'BQnull',\n",
    "    'BQ',\n",
    "    'ELnull',\n",
    "    'EL'\n",
    "    ]:\n",
    "    if col not in features_to_plot:\n",
    "        features_to_plot.append(col)\n",
    "feature_importance=feature_importance[\n",
    "    feature_importance['Feature'].isin(features_to_plot)]\n",
    "feature_importance.sort_values(by=[\"Total Value\",'Model'],inplace=True)\n",
    "feature_importance.rename(columns={'Value':'Importance'},inplace=True)\n",
    "\n",
    "\n",
    "fig = px.bar(feature_importance, x='Importance', y='Feature', facet_col=\"Model\")\n",
    "fig.update_layout(width=1000,height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1203d98-9e99-4ac8-9129-040f2bb14619",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.copy(deep=True)\n",
    "submission['class_1'] = test_preds\n",
    "submission['class_0'] = [1 - x for x in test_preds]\n",
    "submission=submission[['class_0','class_1']]\n",
    "\n",
    "# Save the out of fold predictions on the train dataset\n",
    "x=x['Pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f5a7b-777d-4b54-9c98-9bbd2c09049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_output=False\n",
    "\n",
    "if save_output:\n",
    "    outputFileName = 'v2'\n",
    "    outputFileName += (' ' + str(datetime.today())[:22].replace(':','.'))\n",
    "    x.to_csv(outputFileName + ' ooftrain.csv')\n",
    "    submission.to_csv(outputFileName + '.csv')\n",
    "\n",
    "submission.to_csv('submission.csv')\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
